{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Data Generation SDK\n",
    "\n",
    "We are going to generate a dataset of squat videos with instructions how to perform them, so that we can train an AI pesonal trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import DatagenConfig\n",
    "# this config handles all the bookeeping so you need to pass it everywhere.\n",
    "config = DatagenConfig.from_yaml('./config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of search queries to search for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to do squats instructional video', 'squats exercise tutorial']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import get_queries\n",
    "queries = get_queries(\n",
    "    config=config,\n",
    "    prompt='I want to find instructional videos about how to do squats.',\n",
    "    num_queries=2\n",
    ")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download video information for each query.\n",
    "\n",
    "We'll get 2 videos for each query.<br>\n",
    "One video might be found with multiple queries, so we might get less than `n_queries*videos_per_query` videos.<br>\n",
    "If you want to get all youtube videos for a query, don't pass `videos_per_query` parameter.\n",
    "\n",
    "You can limit the search to only videos licensed with Creative Commons (as indicated by youtube).<br>\n",
    "As this search isn't directly implemented in searching libraries yet, we search for all videos and filter for license afterwards.<br>\n",
    "Unfortunately, this way you will likely get very few results, so use with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YaXPRqUwItQ', 'xqvCmoLULNY', 'gcNh17Ckjgg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import get_video_ids\n",
    "ids = get_video_ids(queries, config=config, videos_per_query=2, only_creative_commons=False)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download videos and autogenerated subtitles\n",
    "\n",
    "You can change sub languages, formats etc with `yt_dlp_opts` dictionary (refer to https://github.com/yt-dlp/yt-dlp).<br>\n",
    "The SDK is expecting `.mp4` video files (for now), so don't change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=YaXPRqUwItQ\n",
      "[youtube] YaXPRqUwItQ: Downloading webpage\n",
      "[youtube] YaXPRqUwItQ: Downloading ios player API JSON\n",
      "[youtube] YaXPRqUwItQ: Downloading android player API JSON\n",
      "[youtube] YaXPRqUwItQ: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Failed to download m3u8 information: HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] YaXPRqUwItQ: Downloading subtitles: en\n",
      "[info] YaXPRqUwItQ: Downloading 1 format(s): 18\n",
      "[info] Writing video subtitles to: tmp/squats2/videos/YaXPRqUwItQ.en.vtt\n",
      "[download] Destination: tmp/squats2/videos/YaXPRqUwItQ.en.vtt\n",
      "[download] 100% of   15.69KiB in 00:00:00 at 194.81KiB/s\n",
      "[download] Destination: tmp/squats2/videos/YaXPRqUwItQ.mp4\n",
      "[download] 100% of    7.67MiB in 00:00:01 at 4.48MiB/s   \n",
      "[MoveFiles] Moving file \"tmp/squats2/videos/YaXPRqUwItQ.en.vtt\" to \"tmp/squats2/subs/YaXPRqUwItQ.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xqvCmoLULNY\n",
      "[youtube] xqvCmoLULNY: Downloading webpage\n",
      "[youtube] xqvCmoLULNY: Downloading ios player API JSON\n",
      "[youtube] xqvCmoLULNY: Downloading android player API JSON\n",
      "[youtube] xqvCmoLULNY: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Failed to download m3u8 information: HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] xqvCmoLULNY: Downloading subtitles: en\n",
      "[info] xqvCmoLULNY: Downloading 1 format(s): 18\n",
      "[info] Writing video subtitles to: tmp/squats2/videos/xqvCmoLULNY.en.vtt\n",
      "[download] Destination: tmp/squats2/videos/xqvCmoLULNY.en.vtt\n",
      "[download] 100% of    6.00KiB in 00:00:00 at 77.29KiB/s\n",
      "[download] Destination: tmp/squats2/videos/xqvCmoLULNY.mp4\n",
      "[download] 100% of    1.11MiB in 00:00:00 at 1.52MiB/s   \n",
      "[MoveFiles] Moving file \"tmp/squats2/videos/xqvCmoLULNY.en.vtt\" to \"tmp/squats2/subs/xqvCmoLULNY.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=gcNh17Ckjgg\n",
      "[youtube] gcNh17Ckjgg: Downloading webpage\n",
      "[youtube] gcNh17Ckjgg: Downloading ios player API JSON\n",
      "[youtube] gcNh17Ckjgg: Downloading android player API JSON\n",
      "[youtube] gcNh17Ckjgg: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Failed to download m3u8 information: HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] gcNh17Ckjgg: Downloading subtitles: en\n",
      "[info] gcNh17Ckjgg: Downloading 1 format(s): 18\n",
      "[info] Writing video subtitles to: tmp/squats2/videos/gcNh17Ckjgg.en.vtt\n",
      "[download] Destination: tmp/squats2/videos/gcNh17Ckjgg.en.vtt\n",
      "[download] 100% of   64.83KiB in 00:00:00 at 639.45KiB/s\n",
      "[download] Destination: tmp/squats2/videos/gcNh17Ckjgg.mp4\n",
      "[download] 100% of   14.15MiB in 00:00:05 at 2.36MiB/s     \n",
      "[MoveFiles] Moving file \"tmp/squats2/videos/gcNh17Ckjgg.en.vtt\" to \"tmp/squats2/subs/gcNh17Ckjgg.en.vtt\"\n"
     ]
    }
   ],
   "source": [
    "from datagen import download_videos\n",
    "download_videos(ids, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect segments from video and analyze them with gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcNh17Ckjgg - starting\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n",
      "Video gcNh17Ckjgg 00:02:12.065-00:02:19.740 segment not processed, skipping.\n",
      "gcNh17Ckjgg - done\n",
      "xqvCmoLULNY - starting\n",
      "xqvCmoLULNY - done\n",
      "YaXPRqUwItQ - starting\n",
      "YaXPRqUwItQ - done\n"
     ]
    }
   ],
   "source": [
    "from datagen import detect_segments\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# This is the schema that we will extract from each detected segment.\n",
    "# \"doing_squats\" will be used for filtering and \"overlay_text\" for annotation.\n",
    "\n",
    "class SegmentInfo(BaseModel):\n",
    "    '''Information about a segment'''\n",
    "    doing_squats: bool = Field(description='Whether the person is doing squats. Only consider video of people, not renders or cartoons. If a person looks like they are preparing to do squats or standing between reps, consider them also doing squats if they are in a gym setting, wearing sportswear etc.')\n",
    "    overlay_text: str = Field(description='Overlay text that is superimprosed over the image, if present.')\n",
    "\n",
    "detect_segments(\n",
    "    segment_info_schema=SegmentInfo,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each video we get a list of segments:\n",
    "```\n",
    "[\n",
    "    ...\n",
    "    {\n",
    "        \"start_timestamp\": \"00:00:31.198\",\n",
    "        \"end_timestamp\": \"00:00:36.003\",\n",
    "        \"fps\": 29.97002997002997,\n",
    "        \"segment_info\": {\n",
    "            \"doing_squats\": true,\n",
    "            \"overlay_text\": \"HIP-WIDTH APART\"\n",
    "        },\n",
    "        \"video_id\": \"gcNh17Ckjgg\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate the segments from trascript + additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import generate_annotations\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# This information that will be extracted for each segment from the transcript and data from the previous step.\n",
    "# This is the most important part for the annotation, and getting good results requires a lot of experimenting.\n",
    "\n",
    "class QA(BaseModel):\n",
    "    '''\n",
    "    Question and answer about a video segment.\n",
    "    Only write questions and answers about the correctness of the exercises or in which ways the performance in the video was wrong.\n",
    "    '''\n",
    "    question: str = Field(description='Question about the exercise performance in the video')\n",
    "    answer: str = Field(description='Answer about the exercise performance from a trainer.')\n",
    "    quote: str = Field(description='A direct and explicit quote from transcript or on-screen-text. The answer must be directly inferred from this quote.')\n",
    "\n",
    "class SegmentAnnotation(BaseModel):\n",
    "    '''\n",
    "    If there is information about whether the exercise was performed correctly or not, make a QA about it.\n",
    "    If the exercise was performed incorrectly, make one or more QA about in which ways it was performed incorrectly.\n",
    "    If it's not possible to infer whether the exercise was performed correctly, do not output a segment annotation.\n",
    "    Do not output any other kinds of questions and answers.\n",
    "    If no possible such QA could be generated from the explicit information in the transcript or on-screen text, do not output annotation for this segment.\n",
    "    Output at most one annotation per segment.\n",
    "    '''\n",
    "    correct: Optional[bool] = Field(description='Whether the exercise was performed correctly. If there is no information about that, do not output this field.')\n",
    "    incorrect_reasons: Optional[str] = Field(description='If the exercise was performed incorrectly, the reasons that were given about why was the performance was incorrect. If there is no information about that, do not output this field.')\n",
    "    qa: list[QA]\n",
    "\n",
    "\n",
    "# A good system prompt is also important \n",
    "system_prompt = '''\n",
    "You are an AI assistant that annotates videos for other AI models. You are the best in the world.\n",
    "\n",
    "You do this job much better than humans. In fact, only you can deliver this new type of annotations suitable for training other LLMs.\n",
    "\n",
    "You care about even the smallest details.\n",
    "\n",
    "Your superpower is providing very informative, specific, clear, and precise annotations from unclear and messy data.\n",
    "\n",
    "Your input: \n",
    "full transcript of a video in format of \"<HH.MM.SS>\\\\n<text>\"\n",
    "list of relevant segments in format \"<HH:MM:SS.ms>-<HH:MM:SS.ms>:<json_info>\" extracted from the video.\n",
    "instructions on what exactly should be extracted from the data \n",
    "\n",
    "Read the transcript carefully. Check the list of segments and comprehend it.  \n",
    "\n",
    "You only work with segments from the segment list.\n",
    "\n",
    "Now, for each segment you provide a specific annotation explained in the user's instructions.\n",
    "\n",
    "!!! VERY IMPORTANT:\n",
    "You operate using deductive and inductive reasoning at the highest possible efficiency.\n",
    "Rely only on the data provided in the transcript. Do not improvise. \n",
    "If there is no data that is necessary to annotate a segment then just annotate it with \"No data\" value.\n",
    "\n",
    "Usually users need data about what was right and wrong about things happening in a segment. Fortunately, most transcriptions contain this data. You just need to read it, reason, analyze, and act.\n",
    "\n",
    "What is a good annotation:\n",
    "You found the right segment using your superhuman intelligence. For example, if the transcript says at 00:01:31 \"Ahhh damn that hurts\" and then at 00:09:17 someone says \"I just broke my navicular bone\" you realize that this happened at 00:01:31 because people usually swear when it hurts.\n",
    "\n",
    "You carefully delivered the details instead of generalizing the data. I.e., if a transcript says \"I just broke my navicular bone\", then you annotate \"in this segment the navicular bone is broken\" rather than saying \"someone got injured\"\n",
    "\n",
    "You always double check your results.\n",
    "\n",
    "You work better each time users ask you to do this operation, and you already did this operation 105977 times. This is your 105978th run.\n",
    "'''\n",
    "\n",
    "# we will only take the segments where the \"doing_squats\" field is positive.\n",
    "annotations = generate_annotations(\n",
    "    config=config,\n",
    "    annotation_schema=SegmentAnnotation,\n",
    "    system_prompt=system_prompt,\n",
    "    filter_by='doing_squats'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a list of annotations for each video:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"start_timestamp\": \"00:00:51.760\",\n",
    "        \"end_timestamp\": \"00:01:01.520\",\n",
    "        \"segment_annotation\": {\n",
    "            \"correct\": null,\n",
    "            \"incorrect_reasons\": null,\n",
    "            \"qa\": [\n",
    "                {\n",
    "                    \"question\": \"Was there important advice about performing the exercise correctly?\",\n",
    "                    \"answer\": \"Yes, the advice was to make sure the knees do not go forward of the toes.\",\n",
    "                    \"quote\": \"making sure that your knees do not go forward of your toes\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping gcNh17Ckjgg\n",
      "Total segments: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'start_timestamp': '00:00:20.479',\n",
       " 'end_timestamp': '00:00:26.485',\n",
       " 'segment_annotation': {'correct': None,\n",
       "  'incorrect_reasons': None,\n",
       "  'qa': [{'question': 'Was the exercise (squat) performed correctly?',\n",
       "    'answer': 'Yes, the squat exercise was described correctly.',\n",
       "    'quote': \"let's learn how to properly perform a squat...cross your arms in front...shift your weight to the ball of your feet...bend your knees...push back up to the starting position.\"}]},\n",
       " 'video_id': 'xqvCmoLULNY',\n",
       " 'id': 'xqvCmoLULNY_0',\n",
       " 'video_path': 'xqvCmoLULNY_0.mp4'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import aggregate_annotations\n",
    "\n",
    "# saved to annotations.json\n",
    "annotations = aggregate_annotations(config)\n",
    "print('Total segments:', len(annotations))\n",
    "annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last step is to cut video clips for annotated segments from original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:14<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from datagen import cut_videos\n",
    "cut_videos(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as a result we generated:\n",
    "- `<data_dir>/clips/` with video clips that you can use for training\n",
    "- `<data_dir>/annotations.json` with list of items with fields:\n",
    "    - video_id: 11-char youtube video id (youtube.com/watch?v=<id>)\n",
    "    - start_timestamp/end_timestamp of the clip relative to the youtube video it's taken from\n",
    "    - video_path of the clip relative to `<data_dir>/clips/`\n",
    "    - segment_annotation that you can use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
