{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Data Generation SDK\n",
    "\n",
    "We are going to generate a dataset of squat videos with instructions how to perform them, so that we can train an AI pesonal trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datagen import DatagenConfig\n",
    "# this config handles all the bookeeping so you need to pass it everywhere.\n",
    "config = DatagenConfig.from_yaml('./config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of search queries to search for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to do squats instructional video', 'squats exercise tutorial']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import get_queries\n",
    "queries = get_queries(\n",
    "    config=config,\n",
    "    prompt='I want to find instructional videos about how to do squats.',\n",
    "    num_queries=2\n",
    ")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download video information for each query.\n",
    "\n",
    "We'll get 2 videos for each query.<br>\n",
    "One video might be found with multiple queries, so we might get less than `n_queries*videos_per_query` videos.<br>\n",
    "If you want to get all youtube videos for a query, don't pass `videos_per_query` parameter.\n",
    "\n",
    "You can limit the search to only videos licensed with Creative Commons (as indicated by youtube).<br>\n",
    "As this search isn't directly implemented in searching libraries yet, we search for all videos and filter for license afterwards.<br>\n",
    "Unfortunately, this way you will likely get very few results, so use with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YaXPRqUwItQ', 'xqvCmoLULNY', 'gcNh17Ckjgg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import get_video_ids\n",
    "ids = get_video_ids(queries, config=config, videos_per_query=2, only_creative_commons=False)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download videos and autogenerated subtitles\n",
    "\n",
    "You can change sub languages, formats etc with `yt_dlp_opts` dictionary (refer to https://github.com/yt-dlp/yt-dlp).<br>\n",
    "The SDK is expecting `.mp4` video files (for now), so don't change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=KvRK5Owqzgw\n",
      "[youtube] KvRK5Owqzgw: Downloading webpage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] KvRK5Owqzgw: Downloading ios player API JSON\n",
      "[youtube] KvRK5Owqzgw: Downloading player 250a2ff7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] KvRK5Owqzgw: nsig extraction failed: Some formats may be missing\n",
      "         n = 6GXUpjC9a5BZO9WmI7aZV2 ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] KvRK5Owqzgw: nsig extraction failed: Some formats may be missing\n",
      "         n = 7Q-BIXb6qWlDcOIHMJOyJB ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] KvRK5Owqzgw: Downloading m3u8 information\n",
      "[info] KvRK5Owqzgw: Downloading subtitles: en\n",
      "[info] KvRK5Owqzgw: Downloading 1 format(s): 614\n",
      "[info] Writing video subtitles to: tmp/squats/videos/KvRK5Owqzgw.en.vtt\n",
      "[download] Destination: tmp/squats/videos/KvRK5Owqzgw.en.vtt\n",
      "[download] 100% of    6.76KiB in 00:00:00 at 87.55KiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 9\n",
      "[download] Destination: tmp/squats/videos/KvRK5Owqzgw.mp4\n",
      "[download] 100% of    8.11MiB in 00:00:08 at 991.81KiB/s               \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/KvRK5Owqzgw.en.vtt\" to \"tmp/squats/subs/KvRK5Owqzgw.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xqvCmoLULNY\n",
      "[youtube] xqvCmoLULNY: Downloading webpage\n",
      "[youtube] xqvCmoLULNY: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xqvCmoLULNY: nsig extraction failed: Some formats may be missing\n",
      "         n = Erw8W7qrJmuVdiP2cLm7d2 ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] xqvCmoLULNY: nsig extraction failed: Some formats may be missing\n",
      "         n = cb9o2LU8eGoNkD4Oaf8DNd ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] xqvCmoLULNY: Downloading m3u8 information\n",
      "[info] xqvCmoLULNY: Downloading subtitles: en\n",
      "[info] xqvCmoLULNY: Downloading 1 format(s): 614\n",
      "[info] Writing video subtitles to: tmp/squats/videos/xqvCmoLULNY.en.vtt\n",
      "[download] Destination: tmp/squats/videos/xqvCmoLULNY.en.vtt\n",
      "[download] 100% of    6.00KiB in 00:00:00 at 155.18KiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 10\n",
      "[download] Destination: tmp/squats/videos/xqvCmoLULNY.mp4\n",
      "[download] 100% of    3.13MiB in 00:00:00 at 5.70MiB/s                   \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/xqvCmoLULNY.en.vtt\" to \"tmp/squats/subs/xqvCmoLULNY.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=gcNh17Ckjgg\n",
      "[youtube] gcNh17Ckjgg: Downloading webpage\n",
      "[youtube] gcNh17Ckjgg: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] gcNh17Ckjgg: nsig extraction failed: Some formats may be missing\n",
      "         n = AWd31sv8mDohRxttDppj1z ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] gcNh17Ckjgg: nsig extraction failed: Some formats may be missing\n",
      "         n = 7XjV9qziow8-RsKbLbg0ll ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] gcNh17Ckjgg: Downloading m3u8 information\n",
      "[info] gcNh17Ckjgg: Downloading subtitles: en\n",
      "[info] gcNh17Ckjgg: Downloading 1 format(s): 616\n",
      "[info] Writing video subtitles to: tmp/squats/videos/gcNh17Ckjgg.en.vtt\n",
      "[download] Destination: tmp/squats/videos/gcNh17Ckjgg.en.vtt\n",
      "[download] 100% of   64.83KiB in 00:00:00 at 1.49MiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 86\n",
      "[download] Destination: tmp/squats/videos/gcNh17Ckjgg.mp4\n",
      "[download] 100% of  139.49MiB in 00:00:06 at 20.39MiB/s                 \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/gcNh17Ckjgg.en.vtt\" to \"tmp/squats/subs/gcNh17Ckjgg.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=YaXPRqUwItQ\n",
      "[youtube] YaXPRqUwItQ: Downloading webpage\n",
      "[youtube] YaXPRqUwItQ: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] YaXPRqUwItQ: nsig extraction failed: Some formats may be missing\n",
      "         n = BkD33Pi_ilvAYBvL4GsX99 ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] YaXPRqUwItQ: nsig extraction failed: Some formats may be missing\n",
      "         n = JAN_VnmXMBEoYPvReeoVve ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] YaXPRqUwItQ: Downloading m3u8 information\n",
      "[info] YaXPRqUwItQ: Downloading subtitles: en\n",
      "[info] YaXPRqUwItQ: Downloading 1 format(s): 616\n",
      "[info] Writing video subtitles to: tmp/squats/videos/YaXPRqUwItQ.en.vtt\n",
      "[download] Destination: tmp/squats/videos/YaXPRqUwItQ.en.vtt\n",
      "[download] 100% of   15.69KiB in 00:00:00 at 423.55KiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 32\n",
      "[download] Destination: tmp/squats/videos/YaXPRqUwItQ.mp4\n",
      "[download] 100% of   28.07MiB in 00:00:03 at 7.34MiB/s                  \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/YaXPRqUwItQ.en.vtt\" to \"tmp/squats/subs/YaXPRqUwItQ.en.vtt\"\n"
     ]
    }
   ],
   "source": [
    "from datagen import download_videos\n",
    "download_videos(['gcNh17Ckjgg', 'KvRK5Owqzgw', 'xqvCmoLULNY', 'YaXPRqUwItQ'], config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect segments from video and analyze them with gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"google/siglip-so400m-patch14-384\").cuda()\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import detect_segments_clip\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# This is the schema that we will extract from each detected segment.\n",
    "# \"doing_squats\" will be used for filtering and \"overlay_text\" for annotation.\n",
    "\n",
    "class SegmentInfo(BaseModel):\n",
    "    '''Information about a segment'''\n",
    "    doing_squats: bool = Field(description='Whether the person is doing squats. Only consider video of people, not renders or cartoons. If a person looks like they are preparing to do squats or standing between reps, consider them also doing squats if they are in a gym setting, wearing sportswear etc.')\n",
    "    # overlay_text: str = Field(description='Overlay text that is superimprosed over the image, if present.')\n",
    "\n",
    "detect_segments_clip(\n",
    "    # segment_info_schema=SegmentInfo,\n",
    "    # video_ids=['KvRK5Owqzgw'],\n",
    "    text_prompts='a person doing squats',\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    fps_sampling=2,\n",
    "    device='cuda',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each video we get a list of segments:\n",
    "```\n",
    "[\n",
    "    ...\n",
    "    {\n",
    "        \"start_timestamp\": \"00:00:31.198\",\n",
    "        \"end_timestamp\": \"00:00:36.003\",\n",
    "        \"fps\": 29.97002997002997,\n",
    "        \"segment_info\": {\n",
    "            \"doing_squats\": true,\n",
    "            \"overlay_text\": \"HIP-WIDTH APART\"\n",
    "        },\n",
    "        \"video_id\": \"gcNh17Ckjgg\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate the segments from trascript + additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcNh17Ckjgg - started\n",
      "gcNh17Ckjgg part 0 - started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcNh17Ckjgg part 1 - started\n",
      "gcNh17Ckjgg part 2 - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:39<04:58, 99.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcNh17Ckjgg - done\n",
      "YaXPRqUwItQ - started\n",
      "YaXPRqUwItQ part 0 - started\n",
      "YaXPRqUwItQ part 1 - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:05<01:52, 56.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YaXPRqUwItQ - done\n",
      "xqvCmoLULNY - started\n",
      "xqvCmoLULNY part 0 - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [02:24<00:39, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xqvCmoLULNY - done\n",
      "KvRK5Owqzgw - started\n",
      "KvRK5Owqzgw part 0 - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:32<00:00, 38.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KvRK5Owqzgw - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datagen.annotate import generate_annotations, generate_clues\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "human_prompt = \"\"\"User's instructions:\n",
    "The initial video was a tutorial about how to perform squats. \n",
    "All *parts* below contain a video footage of a person doing squats. \n",
    "I need to find as much data as possible about HOW THIS PERSON PERFORMS SQUATS. \n",
    "I'm interested in how a person in a segment doings squats. What mistakes they make. What improvements they show. \n",
    "What they do correctly. What could be improved.\n",
    "Please, help me find relevant clues.\n",
    "\"\"\"\n",
    "\n",
    "# The technique feedback should be in the form of a fitness instructor speaking to a trainee.\n",
    "# The feedback should be exactly to the exercise performance shown in the segment and not to other segments.\n",
    "# Good technique feedback:\n",
    "# - Ensure your knees are in line with your toes and your back is straight while squatting.\n",
    "# Bad technique feedback:\n",
    "# - The video emphasizes the importance of following four easy steps to improve squat performance and muscle growth.\n",
    "\n",
    "class Clue(BaseModel):\n",
    "    '''\n",
    "        Good local clues examples: [\n",
    "      {\n",
    "        \"id\": \"LC1\",\n",
    "        \"timestamp\": \"00:00:19\",\n",
    "        \"text\": \"exercises do them wrong and instead of\",\n",
    "        \"analysis\": \"This phrase introduces the concept of incorrect exercise form, setting the stage for a demonstration of improper technique.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LC2\",\n",
    "        \"timestamp\": \"00:00:21\",\n",
    "        \"text\": \"growing nice quads and glutes you'll\",\n",
    "        \"analysis\": \"Mentions the expected benefits of proper squats (muscle growth), implying that these benefits won't be achieved with incorrect form.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LC3\",\n",
    "        \"timestamp\": \"00:00:22\",\n",
    "        \"text\": \"feel aches and pains in your knees your\",\n",
    "        \"analysis\": \"Directly states negative consequences of improper form, strongly suggesting that this segment demonstrates incorrect technique.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LC4\",\n",
    "        \"timestamp\": \"00:00:24\",\n",
    "        \"text\": \"lower back and even your shoulders\",\n",
    "        \"analysis\": \"Continuation of LC3, emphasizing multiple areas of potential pain from improper form.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LC5\",\n",
    "        \"timestamp\": \"00:00:26\",\n",
    "        \"text\": \"let's see how to do it correctly\",\n",
    "        \"analysis\": \"This phrase suggests a transition is about to occur. The incorrect form has been shown, and correct form will follow.\"\n",
    "      }\n",
    "    ]\n",
    "    Good global clues examples: [\n",
    "      {\n",
    "        \"id\": \"GC1\",\n",
    "        \"timestamp\": \"00:00:08\",\n",
    "        \"text\": \"the most common mistake\",\n",
    "        \"analysis\": \"Introduces the idea that a frequent error will be discussed. This sets up the expectation for a demonstration of this mistake.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"GC2\",\n",
    "        \"timestamp\": \"00:00:10\",\n",
    "        \"text\": \"is when your heels are\",\n",
    "        \"analysis\": \"Begins to describe the specific error related to heel position.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"GC3\",\n",
    "        \"timestamp\": \"00:00:12\",\n",
    "        \"text\": \"in the air and not attached to the ground\",\n",
    "        \"analysis\": \"Completes the description of the common mistake. This strongly suggests that the segment will demonstrate this specific error.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"GC4\",\n",
    "        \"timestamp\": \"00:01:01\",\n",
    "        \"text\": \"butt wink is a problem\",\n",
    "        \"analysis\": \"Introduces another potential issue in squat form. While this comes after the segment, it might be relevant if the demonstration includes multiple errors.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"GC5\",\n",
    "        \"timestamp\": \"00:01:03\",\n",
    "        \"text\": \"it can lead to the back pain\",\n",
    "        \"analysis\": \"Connects to LC3 and LC4, which mention back pain. This strengthens the possibility that 'butt wink' is also demonstrated in the segment.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"GC6\",\n",
    "        \"timestamp\": \"00:01:06\",\n",
    "        \"text\": \"so don't do that\",\n",
    "        \"analysis\": \"Reinforces that the previously mentioned 'butt wink' is an error to be avoided, consistent with the segment's focus on incorrect form.\"\n",
    "      }\n",
    "    ]\n",
    "    '''\n",
    "    id: str = Field(description='LC1,LC2... for local clues, GC1,GC2... for global clues')\n",
    "    timestamp: str = Field(description='mandatory for local and global clues, optional for logical inference or additional observations')\n",
    "    text: str = Field(description='the text taken from the transcript')\n",
    "    analysis: str = Field(description='interpretation of the text for improving squat techique')\n",
    "\n",
    "class AdditionalInformation(BaseModel):\n",
    "    '''\n",
    "    Good logical inference examples:\n",
    "    [\n",
    "      {\n",
    "        \"id\": \"LI1\",\n",
    "        \"description\": \"Primary Demonstration of Heel Lift\",\n",
    "        \"details\": \"Given that GC1-GC3 describe the 'most common mistake' as heels lifting off the ground, and this description immediately precedes our segment, it's highly probable that this is the primary error being demonstrated. This is further supported by the segment's focus on incorrect form (LC1-LC4).\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LI2\",\n",
    "        \"description\": \"Multiple Error Demonstration\",\n",
    "        \"details\": \"While heel lift is likely the primary focus, the mention of multiple pain points (knees, lower back, shoulders in LC3-LC4) suggests that the demonstrator may be exhibiting several forms of incorrect technique simultaneously. This comprehensive 'what not to do' approach would be pedagogically effective.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LI3\",\n",
    "        \"description\": \"Possible Inclusion of 'Butt Wink'\",\n",
    "        \"details\": \"Although 'butt wink' is mentioned after our segment (GC4-GC6), its connection to back pain (which is mentioned in LC4) raises the possibility that this error is also present in the demonstration. The instructor may be showing multiple errors early on, then breaking them down individually later.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LI4\",\n",
    "        \"description\": \"Segment Placement in Overall Video Structure\",\n",
    "        \"details\": \"The segment's position (starting at 00:00:19) and the phrase 'let's see how to do it correctly' (LC5) at the end suggest this is an early, foundational part of the video. It likely serves to grab attention by showing common mistakes before transitioning to proper form instruction.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"LI5\",\n",
    "        \"description\": \"Intentional Exaggeration of Errors\",\n",
    "        \"details\": \"Given the educational nature of the video, it's plausible that the demonstrator is intentionally exaggerating the incorrect form. This would make the errors more obvious to viewers and enhance the contrast with correct form shown later.\"\n",
    "      }\n",
    "    ]\n",
    "    \n",
    "    Good additional observations examples: [\n",
    "      {\n",
    "        \"id\": \"AO1\",\n",
    "        \"description\": \"Absence of Technical Terms\",\n",
    "        \"details\": \"The transcript uses lay terms ('nice quads and glutes') rather than technical anatomical language. This suggests the video is targeted at a general audience rather than fitness professionals.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"AO2\",\n",
    "        \"description\": \"Emphasis on Consequences\",\n",
    "        \"details\": \"The immediate focus on negative outcomes (pain, lack of muscle growth) indicates a motivational approach, likely to encourage viewers to pay close attention to form.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"AO3\",\n",
    "        \"description\": \"Potential Visual Cues\",\n",
    "        \"details\": \"While we can't see the video, the specific mentions of body parts (heels, knees, lower back, shoulders) suggest there may be visual indicators or graphics highlighting these areas during the demonstration.\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"AO4\",\n",
    "        \"description\": \"Instructional Flow\",\n",
    "        \"details\": \"The structure (common mistake → demonstration of errors → transition to correct form) follows a classic 'what not to do, then what to do' instructional pattern, which is effective for physical skills.\"\n",
    "      }\n",
    "    ]\n",
    "    '''\n",
    "    id: str = Field(description='LI1,LI2,... for logical inference, AO1,AO2,... for additional observations.')\n",
    "    description: str = Field(description='A concise name of the information')\n",
    "    details: str = Field(description='a more verbose description related to improving squat technique')\n",
    "\n",
    "class SegmentAnnotation(BaseModel):\n",
    "    local_clues: Optional[list[Clue]] = Field(description='Provide here all the clues about this time segment. Explain your logic in “If A then B” style. E.g., \"Dan says Tony was doing squats right while Mary did it wrong, and according to the conversation the person in this segment is Tony\". The clue is considered local if its located inside the segment or is overlapping with it. Be excessive, provide all the information you have found. Provide specific instructions from the transcript with timecodes.')\n",
    "    global_clues: Optional[list[Clue]] = Field(description='Relevant clues are also scattered across the entire video. Provide here all the global clues about this time segment. \"Global\" means these clues were found across the entire video. E.g., the segment happens at 00:00:15 and the clue was found at 01:19:11. Explain your logic, especially why these clues are relevant to this particular segment. Be excessive, provide all the information you have found. Provide specific instructions from the transcript with timecodes.')\n",
    "    # \n",
    "    # specifically the clues that you have extracted\n",
    "    # techique_feedback: Optional[str] = Field(description='You are a fitness instructor. You are watching the squats performance of a person and saying them feedback on how good they are doing and what they can do better. The instructions for each segments should be self contained and not referencing other segments. If you dont have enough information to generate these instructions, do not say anything instead of saying that you dont know. Double check yourself to make sure that the feedback from the transcript corresponds to the timestamps of the segment.')\n",
    "    logical_inferences: Optional[list[AdditionalInformation]] = Field(description='Build logical inferences for clues you found before. Use technical language. Be clear and consistent.')\n",
    "    additional_observations: Optional[list[AdditionalInformation]] = Field(description='Any other observations that could help interpret the part of the video.')\n",
    "\n",
    "    # instructions: Optional[str] = Field(description='After extracting clues, generate instructions using them. The instructions should be in the form of feedback to what is happening in the video - whether the squats are performed correctly, what is correct in the form and what could be improved. If no such instructions could be generated, skip the segment and do not output any instructions. They should be worded in the way a fitness coach would provide them. This text should read as though a coach is speaking, it should not contain anything that a person wouldnt say, eg \"no instructions are provided here\". If there is no clues or its impossible to generate instructions, skip the segment, and do not write anything.')\n",
    "    # correct_technique: Optional[bool] = Field(description='based on the provided transcript, infer whether the person in the segment performs the exercise correctly or incorrectly')\n",
    "\n",
    "\n",
    "    # clues_critic: Optional[str] = Field(description='Criticize all clues here.')\n",
    "    # segment_data: Optional[str] = Field(description='Provide the final segment data here: details about this person body, mistakes and correct things about the squat, observations, recommendations, potential improvements, etc.')\n",
    "\n",
    "\n",
    "\n",
    "# we will only take the segments where the \"doing_squats\" field is positive.\n",
    "clues = generate_clues(\n",
    "    config=config,\n",
    "    annotation_schema=SegmentAnnotation,\n",
    "    human_prompt=human_prompt,\n",
    "    segments_per_call=5,\n",
    "    raise_on_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcNh17Ckjgg - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:25<01:15, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcNh17Ckjgg - done\n",
      "YaXPRqUwItQ - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:35<00:32, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YaXPRqUwItQ - done\n",
      "xqvCmoLULNY - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:37<00:09,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xqvCmoLULNY - done\n",
      "KvRK5Owqzgw - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:44<00:00, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KvRK5Owqzgw - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datagen.annotate import generate_annotations, generate_clues\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# This information that will be extracted for each segment from the transcript and data from the previous step.\n",
    "# This is the most important part for the annotation, and getting good results requires a lot of experimenting.\n",
    "\n",
    "import inspect\n",
    "\n",
    "human_prompt = '''\n",
    "You are given a JSON object that contains clues about segments of a video with timecodes.\n",
    "!!!! For each segment provided in a JSON object you need to answer on the following questions:\n",
    "1. Given the data found in the JSON object, what is a probability that this part contains a footage of a person doing squats? [the answer could be only \"High\",\"Medium\" or \"Low\"]\n",
    "2. Given the data found in the JSON object and even if the answer on the previous question is \"Low\", does this person do squats right, wrong, or mixed? [the answer could be only \"Right\", \"Wrong\", and \"Mixed\"]\n",
    "3. Given the data found in the JSON object, what exactly does thing person do right and/or wrong regarding their squats technique? [the answer should be clear and focused on body parts]\n",
    "4. If the answer on the previous question contains description of wrong technique, explain how to fix these mistakes using your \"own knowledge\" like you are a sports coach.\n",
    "'''\n",
    "\n",
    "# class QA(BaseModel):\n",
    "#     '''\n",
    "#     Question and answer about a video segment.\n",
    "#     Only write questions and answers about the correctness of the exercises or in which ways the performance in the video was wrong.\n",
    "#     '''\n",
    "#     question: str = Field(description='Question about the exercise performance in the video')\n",
    "#     answer: str = Field(description='Answer about the exercise performance from a trainer.')\n",
    "#     quote: str = Field(description='A direct and explicit quote from transcript or on-screen-text. The answer must be directly inferred from this quote.')\n",
    "\n",
    "# '''\n",
    "#   This is an example of a good analysis:\n",
    "\n",
    "#   —> GOOD EXAMPLE STARTS HERE:\n",
    "\n",
    "# {\n",
    "# \"start_timestamp\":\"00:00:00.000\",\n",
    "# \"end_timestamp\":\"00:00:10.000\",\n",
    "# \"squats_probability\":\"High\",\n",
    "# \"squats_technique\":\"Mixed\",\n",
    "# \"squats_content\": [{\"wrong\":\"Knees Caving In: This can stress the knees and reduce effectiveness\", \"correction\":\"Focus on keeping knees aligned with your toes.\"},\n",
    "#                     {\"wrong\":\"Rounding the Back: This increases the risk of back injuries\", \"correction\":\"Keep your chest up and maintain a neutral spine throughout the movement.\"},\n",
    "#                     {\"wrong\":\"Heels Lifting Off the Ground: This shifts the weight forward, reducing stability\", \"correction\":\" Keep your weight on your heels and press through them as you rise.\"},\n",
    "#                     {\"right\":\"Chest and Shoulders: The chest is up, and the shoulders are back, maintaining an upright torso.\", \"correction\":\"No need.\"}]\n",
    "#                     }\n",
    "#     —> GOOD EXAMPLE ENDS HERE\n",
    "\n",
    "#     This is an example of a bad analysis:\n",
    "\n",
    "#     —> BAD EXAMPLE STARTS HERE\n",
    "\n",
    "# {\n",
    "# \"start_timestamp\":\"00:00:00\",\n",
    "# \"end_timestamp\":\"00:10:00\",\n",
    "# \"squats_probability\":\"maybe\",\n",
    "# \"squats_technique\":\"okay-ish\",\n",
    "# \"squats_content\": [{\"wrong\":\"knees\", \"correction\":\"fix knees\"},\n",
    "#                    {\"wrong\":\"back looks funny\", \"correction\":\"make back better\"},\n",
    "#                    {\"wrong\":\"feet are doing something\", \"correction\":\"feet should be different\"},\n",
    "#                    {\"right\":\"arms\", \"correction\":\"arms are fine i think\"}]\n",
    "# }\n",
    "#     —> BAD EXAMPLE ENDS HERE\n",
    "\n",
    "# '''\n",
    "\n",
    "class SegmentFeedback(BaseModel):\n",
    "    '''\n",
    "    You are a fitness trainer giving feedback on what was right, wrong, and what could be improved.\n",
    "    Talk as you would talk to a trainee, but avoid excessive language or irrelevant banter.\n",
    "\n",
    "—> GOOD EXAMPLES:\n",
    "    \"wrong\":\"Knees caving in: This can stress the knees and reduce effectiveness\"\n",
    "    \"correction\":\"Focus on keeping knees aligned with your toes.\"\n",
    "    \"wrong\":\"Rounding the back: This increases the risk of back injuries\"\n",
    "    \"correction\":\"Keep your chest up and maintain a neutral spine throughout the movement.\"\n",
    "    \"wrong\":\"Heels are lifting off the ground: this shifts the weight forward, reducing stability\"\n",
    "    \"correction\":\" Keep your weight on your heels and press through them as you rise.\"\n",
    "    \"right\":\"Chest and shoulders: The chest is up, and the shoulders are back, maintaining an upright torso.\"\n",
    "    \"correction\":null\n",
    "—> BAD EXAMPLES:\n",
    "    \"wrong\":\"knees\"\n",
    "    \"correction\":\"fix knees\"\n",
    "    \"wrong\":\"back looks funny\"\n",
    "    \"correction\":\"make back better\"\n",
    "    \"wrong\":\"feet are doing something\"\n",
    "    \"correction\":\"feet should be different\"\n",
    "    \"right\":\"arms\"\n",
    "    \"correction\":\"arms are fine i think\"\n",
    "—> BAD EXAMPLES END HERE\n",
    "    '''\n",
    "    right: Optional[str] = Field(description='what was right in the performance')\n",
    "    wrong: Optional[str] = Field(description='what was wrong in the performance')\n",
    "    correction: Optional[str] = Field(description='how and in what ways it the performance could be improved')\n",
    "\n",
    "# The segment timestamps are taken from the provided information.\n",
    "class SegmentAnnotation(BaseModel):\n",
    "    '''\n",
    "    This annotation is generated exclusively from the provided information about this specific segment.\n",
    "    Dont pay attention to information about other segments.\n",
    "    '''\n",
    "    squats_probability: Optional[str] = Field(description='how high is the probability that the person is doing squats in the segment: low, medium, high, unknown(null)')\n",
    "    squats_technique_correctness: Optional[bool] = Field(description='bollean correctness of the squat technique.')\n",
    "    squats_feedback: SegmentFeedback = Field(description='what was right and wrong in the squat perfomance in the segment. When the technique is incorrect, provide instructions how to correct them.')\n",
    "\n",
    "# we will only take the segments where the \"doing_squats\" field is positive.\n",
    "annotations = generate_annotations(\n",
    "    # human_prompt=human_prompt,\n",
    "    config=config,\n",
    "    annotation_schema=SegmentAnnotation,\n",
    "    # filter_by='doing_squats'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a list of annotations for each video:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"start_timestamp\": \"00:00:51.760\",\n",
    "        \"end_timestamp\": \"00:01:01.520\",\n",
    "        \"segment_annotation\": {\n",
    "            \"correct\": null,\n",
    "            \"incorrect_reasons\": null,\n",
    "            \"qa\": [\n",
    "                {\n",
    "                    \"question\": \"Was there important advice about performing the exercise correctly?\",\n",
    "                    \"answer\": \"Yes, the advice was to make sure the knees do not go forward of the toes.\",\n",
    "                    \"quote\": \"making sure that your knees do not go forward of your toes\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping gcNh17Ckjgg\n",
      "Total segments: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'start_timestamp': '00:00:20.479',\n",
       " 'end_timestamp': '00:00:26.485',\n",
       " 'segment_annotation': {'correct': None,\n",
       "  'incorrect_reasons': None,\n",
       "  'qa': [{'question': 'Was the exercise (squat) performed correctly?',\n",
       "    'answer': 'Yes, the squat exercise was described correctly.',\n",
       "    'quote': \"let's learn how to properly perform a squat...cross your arms in front...shift your weight to the ball of your feet...bend your knees...push back up to the starting position.\"}]},\n",
       " 'video_id': 'xqvCmoLULNY',\n",
       " 'id': 'xqvCmoLULNY_0',\n",
       " 'video_path': 'xqvCmoLULNY_0.mp4'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import aggregate_annotations\n",
    "\n",
    "# saved to annotations.json\n",
    "annotations = aggregate_annotations(config)\n",
    "print('Total segments:', len(annotations))\n",
    "annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last step is to cut video clips for annotated segments from original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:14<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from datagen import cut_videos\n",
    "cut_videos(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as a result we generated:\n",
    "- `<data_dir>/clips/` with video clips that you can use for training\n",
    "- `<data_dir>/annotations.json` with list of items with fields:\n",
    "    - video_id: 11-char youtube video id (youtube.com/watch?v=<id>)\n",
    "    - start_timestamp/end_timestamp of the clip relative to the youtube video it's taken from\n",
    "    - video_path of the clip relative to `<data_dir>/clips/`\n",
    "    - segment_annotation that you can use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
