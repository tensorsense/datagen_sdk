{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Data Generation SDK\n",
    "\n",
    "We are going to generate a dataset of squat videos with instructions how to perform them, so that we can train an AI pesonal trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datagen import DatagenConfig\n",
    "# this config handles all the bookeeping so you need to pass it everywhere.\n",
    "config = DatagenConfig.from_yaml('./config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of search queries to search for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to do squats instructional video', 'squats exercise tutorial']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import get_queries\n",
    "queries = get_queries(\n",
    "    config=config,\n",
    "    prompt='I want to find instructional videos about how to do squats.',\n",
    "    num_queries=2\n",
    ")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download video information for each query.\n",
    "\n",
    "We'll get 2 videos for each query.<br>\n",
    "One video might be found with multiple queries, so we might get less than `n_queries*videos_per_query` videos.<br>\n",
    "If you want to get all youtube videos for a query, don't pass `videos_per_query` parameter.\n",
    "\n",
    "You can limit the search to only videos licensed with Creative Commons (as indicated by youtube).<br>\n",
    "As this search isn't directly implemented in searching libraries yet, we search for all videos and filter for license afterwards.<br>\n",
    "Unfortunately, this way you will likely get very few results, so use with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['YaXPRqUwItQ', 'xqvCmoLULNY', 'gcNh17Ckjgg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import get_video_ids\n",
    "ids = get_video_ids(queries, config=config, videos_per_query=2, only_creative_commons=False)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download videos and autogenerated subtitles\n",
    "\n",
    "You can change sub languages, formats etc with `yt_dlp_opts` dictionary (refer to https://github.com/yt-dlp/yt-dlp).<br>\n",
    "The SDK is expecting `.mp4` video files (for now), so don't change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=KvRK5Owqzgw\n",
      "[youtube] KvRK5Owqzgw: Downloading webpage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] KvRK5Owqzgw: Downloading ios player API JSON\n",
      "[youtube] KvRK5Owqzgw: Downloading player 250a2ff7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] KvRK5Owqzgw: nsig extraction failed: Some formats may be missing\n",
      "         n = 6GXUpjC9a5BZO9WmI7aZV2 ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] KvRK5Owqzgw: nsig extraction failed: Some formats may be missing\n",
      "         n = 7Q-BIXb6qWlDcOIHMJOyJB ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] KvRK5Owqzgw: Downloading m3u8 information\n",
      "[info] KvRK5Owqzgw: Downloading subtitles: en\n",
      "[info] KvRK5Owqzgw: Downloading 1 format(s): 614\n",
      "[info] Writing video subtitles to: tmp/squats/videos/KvRK5Owqzgw.en.vtt\n",
      "[download] Destination: tmp/squats/videos/KvRK5Owqzgw.en.vtt\n",
      "[download] 100% of    6.76KiB in 00:00:00 at 87.55KiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 9\n",
      "[download] Destination: tmp/squats/videos/KvRK5Owqzgw.mp4\n",
      "[download] 100% of    8.11MiB in 00:00:08 at 991.81KiB/s               \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/KvRK5Owqzgw.en.vtt\" to \"tmp/squats/subs/KvRK5Owqzgw.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xqvCmoLULNY\n",
      "[youtube] xqvCmoLULNY: Downloading webpage\n",
      "[youtube] xqvCmoLULNY: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xqvCmoLULNY: nsig extraction failed: Some formats may be missing\n",
      "         n = Erw8W7qrJmuVdiP2cLm7d2 ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] xqvCmoLULNY: nsig extraction failed: Some formats may be missing\n",
      "         n = cb9o2LU8eGoNkD4Oaf8DNd ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] xqvCmoLULNY: Downloading m3u8 information\n",
      "[info] xqvCmoLULNY: Downloading subtitles: en\n",
      "[info] xqvCmoLULNY: Downloading 1 format(s): 614\n",
      "[info] Writing video subtitles to: tmp/squats/videos/xqvCmoLULNY.en.vtt\n",
      "[download] Destination: tmp/squats/videos/xqvCmoLULNY.en.vtt\n",
      "[download] 100% of    6.00KiB in 00:00:00 at 155.18KiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 10\n",
      "[download] Destination: tmp/squats/videos/xqvCmoLULNY.mp4\n",
      "[download] 100% of    3.13MiB in 00:00:00 at 5.70MiB/s                   \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/xqvCmoLULNY.en.vtt\" to \"tmp/squats/subs/xqvCmoLULNY.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=gcNh17Ckjgg\n",
      "[youtube] gcNh17Ckjgg: Downloading webpage\n",
      "[youtube] gcNh17Ckjgg: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] gcNh17Ckjgg: nsig extraction failed: Some formats may be missing\n",
      "         n = AWd31sv8mDohRxttDppj1z ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] gcNh17Ckjgg: nsig extraction failed: Some formats may be missing\n",
      "         n = 7XjV9qziow8-RsKbLbg0ll ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] gcNh17Ckjgg: Downloading m3u8 information\n",
      "[info] gcNh17Ckjgg: Downloading subtitles: en\n",
      "[info] gcNh17Ckjgg: Downloading 1 format(s): 616\n",
      "[info] Writing video subtitles to: tmp/squats/videos/gcNh17Ckjgg.en.vtt\n",
      "[download] Destination: tmp/squats/videos/gcNh17Ckjgg.en.vtt\n",
      "[download] 100% of   64.83KiB in 00:00:00 at 1.49MiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 86\n",
      "[download] Destination: tmp/squats/videos/gcNh17Ckjgg.mp4\n",
      "[download] 100% of  139.49MiB in 00:00:06 at 20.39MiB/s                 \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/gcNh17Ckjgg.en.vtt\" to \"tmp/squats/subs/gcNh17Ckjgg.en.vtt\"\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=YaXPRqUwItQ\n",
      "[youtube] YaXPRqUwItQ: Downloading webpage\n",
      "[youtube] YaXPRqUwItQ: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] YaXPRqUwItQ: nsig extraction failed: Some formats may be missing\n",
      "         n = BkD33Pi_ilvAYBvL4GsX99 ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] YaXPRqUwItQ: nsig extraction failed: Some formats may be missing\n",
      "         n = JAN_VnmXMBEoYPvReeoVve ; player = https://www.youtube.com/s/player/250a2ff7/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] YaXPRqUwItQ: Downloading m3u8 information\n",
      "[info] YaXPRqUwItQ: Downloading subtitles: en\n",
      "[info] YaXPRqUwItQ: Downloading 1 format(s): 616\n",
      "[info] Writing video subtitles to: tmp/squats/videos/YaXPRqUwItQ.en.vtt\n",
      "[download] Destination: tmp/squats/videos/YaXPRqUwItQ.en.vtt\n",
      "[download] 100% of   15.69KiB in 00:00:00 at 423.55KiB/s\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 32\n",
      "[download] Destination: tmp/squats/videos/YaXPRqUwItQ.mp4\n",
      "[download] 100% of   28.07MiB in 00:00:03 at 7.34MiB/s                  \n",
      "[MoveFiles] Moving file \"tmp/squats/videos/YaXPRqUwItQ.en.vtt\" to \"tmp/squats/subs/YaXPRqUwItQ.en.vtt\"\n"
     ]
    }
   ],
   "source": [
    "from datagen import download_videos\n",
    "download_videos(['gcNh17Ckjgg', 'KvRK5Owqzgw', 'xqvCmoLULNY', 'YaXPRqUwItQ'], config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect segments from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"google/siglip-so400m-patch14-384\").cuda()\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import detect_segments_clip\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "detect_segments_clip(\n",
    "    # video_ids=['KvRK5Owqzgw'],\n",
    "    text_prompts='a person doing squats',\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    fps_sampling=2,\n",
    "    device='cuda',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each video we get a list of segments:\n",
    "```\n",
    "[\n",
    "    ...\n",
    "    {\n",
    "        \"start_timestamp\": \"00:00:32.500\",\n",
    "        \"end_timestamp\": \"00:00:41.500\",\n",
    "        \"fps\": 29.97002997002997,\n",
    "        \"segment_info\": null,\n",
    "        \"video_id\": \"KvRK5Owqzgw\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotaion step 1: extract information from transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.v1.main.SegmentAnnotation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen.clues import generate_clues_dataclass\n",
    "SegmentAnnotation = generate_clues_dataclass(prompt='making plov', config=config)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(SegmentAnnotation.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KvRK5Owqzgw - started\n",
      "KvRK5Owqzgw part 0 - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KvRK5Owqzgw - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datagen import generate_clues\n",
    "\n",
    "clues = generate_clues(\n",
    "    config=config,\n",
    "    annotation_schema=SegmentAnnotation,\n",
    "    # human_prompt=human_prompt,\n",
    "    segments_per_call=5,\n",
    "    raise_on_error=True, # interrupt when encountering an error. Useful for debugging.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotaion step 2: extract information from transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KvRK5Owqzgw - started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KvRK5Owqzgw - done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datagen import generate_annotations\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# This information that will be extracted for each segment from the transcript and data from the previous step.\n",
    "# This is the most important part for the annotation, and getting good results requires a lot of experimenting.\n",
    "\n",
    "import inspect\n",
    "\n",
    "human_prompt = '''\n",
    "You are given a JSON object that contains clues about segments of a video with timecodes.\n",
    "!!!! For each segment provided in a JSON object you need to answer on the following questions:\n",
    "1. Given the data found in the JSON object, what is a probability that this part contains a footage of a person doing squats? [the answer could be only \"High\",\"Medium\" or \"Low\"]\n",
    "2. Given the data found in the JSON object and even if the answer on the previous question is \"Low\", does this person do squats right, wrong, or mixed? [the answer could be only \"Right\", \"Wrong\", and \"Mixed\"]\n",
    "3. Given the data found in the JSON object, what exactly does thing person do right and/or wrong regarding their squats technique? [the answer should be clear and focused on body parts]\n",
    "4. If the answer on the previous question contains description of wrong technique, explain how to fix these mistakes using your \"own knowledge\" like you are a sports coach.\n",
    "'''\n",
    "\n",
    "class SegmentFeedback(BaseModel):\n",
    "    '''\n",
    "    You are a fitness trainer giving feedback on what was right, wrong, and what could be improved.\n",
    "    Talk as you would talk to a trainee, but avoid excessive language or irrelevant banter.\n",
    "\n",
    "—> GOOD EXAMPLES:\n",
    "    \"wrong\":\"Knees caving in: This can stress the knees and reduce effectiveness\"\n",
    "    \"correction\":\"Focus on keeping knees aligned with your toes.\"\n",
    "    \"wrong\":\"Rounding the back: This increases the risk of back injuries\"\n",
    "    \"correction\":\"Keep your chest up and maintain a neutral spine throughout the movement.\"\n",
    "    \"wrong\":\"Heels are lifting off the ground: this shifts the weight forward, reducing stability\"\n",
    "    \"correction\":\" Keep your weight on your heels and press through them as you rise.\"\n",
    "    \"right\":\"Chest and shoulders: The chest is up, and the shoulders are back, maintaining an upright torso.\"\n",
    "    \"correction\":null\n",
    "—> BAD EXAMPLES:\n",
    "    \"wrong\":\"knees\"\n",
    "    \"correction\":\"fix knees\"\n",
    "    \"wrong\":\"back looks funny\"\n",
    "    \"correction\":\"make back better\"\n",
    "    \"wrong\":\"feet are doing something\"\n",
    "    \"correction\":\"feet should be different\"\n",
    "    \"right\":\"arms\"\n",
    "    \"correction\":\"arms are fine i think\"\n",
    "—> BAD EXAMPLES END HERE\n",
    "    '''\n",
    "    right: Optional[str] = Field(description='what was right in the performance')\n",
    "    wrong: Optional[str] = Field(description='what was wrong in the performance')\n",
    "    correction: Optional[str] = Field(description='how and in what ways it the performance could be improved')\n",
    "\n",
    "# The segment timestamps are taken from the provided information.\n",
    "class SegmentAnnotation(BaseModel):\n",
    "    '''\n",
    "    This annotation is generated exclusively from the provided information about this specific segment.\n",
    "    Dont pay attention to information about other segments.\n",
    "    '''\n",
    "    # squats_probability: Optional[str] = Field(description='how high is the probability that the person is doing squats in the segment: low, medium, high, unknown(null)')\n",
    "    squats_technique_correctness: Optional[bool] = Field(description='bollean correctness of the squat technique.')\n",
    "    squats_feedback: SegmentFeedback = Field(description='what was right and wrong in the squat perfomance in the segment. When the technique is incorrect, provide instructions how to correct them.')\n",
    "\n",
    "# we will only take the segments where the \"doing_squats\" field is positive.\n",
    "annotations = generate_annotations(\n",
    "    human_prompt=human_prompt,\n",
    "    config=config,\n",
    "    annotation_schema=SegmentAnnotation,\n",
    "    # filter_by='doing_squats'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a list of annotations for each video:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"start_timestamp\": \"00:00:51.760\",\n",
    "        \"end_timestamp\": \"00:01:01.520\",\n",
    "        \"segment_annotation\": {\n",
    "            \"correct\": null,\n",
    "            \"incorrect_reasons\": null,\n",
    "            \"qa\": [\n",
    "                {\n",
    "                    \"question\": \"Was there important advice about performing the exercise correctly?\",\n",
    "                    \"answer\": \"Yes, the advice was to make sure the knees do not go forward of the toes.\",\n",
    "                    \"quote\": \"making sure that your knees do not go forward of your toes\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping gcNh17Ckjgg\n",
      "Total segments: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'start_timestamp': '00:00:20.479',\n",
       " 'end_timestamp': '00:00:26.485',\n",
       " 'segment_annotation': {'correct': None,\n",
       "  'incorrect_reasons': None,\n",
       "  'qa': [{'question': 'Was the exercise (squat) performed correctly?',\n",
       "    'answer': 'Yes, the squat exercise was described correctly.',\n",
       "    'quote': \"let's learn how to properly perform a squat...cross your arms in front...shift your weight to the ball of your feet...bend your knees...push back up to the starting position.\"}]},\n",
       " 'video_id': 'xqvCmoLULNY',\n",
       " 'id': 'xqvCmoLULNY_0',\n",
       " 'video_path': 'xqvCmoLULNY_0.mp4'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import aggregate_annotations\n",
    "\n",
    "# saved to annotations.json\n",
    "annotations = aggregate_annotations(config)\n",
    "print('Total segments:', len(annotations))\n",
    "annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last step is to cut video clips for annotated segments from original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:14<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from datagen import cut_videos\n",
    "cut_videos(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as a result we generated:\n",
    "- `<data_dir>/clips/` with video clips that you can use for training\n",
    "- `<data_dir>/annotations.json` with list of items with fields:\n",
    "    - video_id: 11-char youtube video id (youtube.com/watch?v=<id>)\n",
    "    - start_timestamp/end_timestamp of the clip relative to the youtube video it's taken from\n",
    "    - video_path of the clip relative to `<data_dir>/clips/`\n",
    "    - segment_annotation that you can use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
