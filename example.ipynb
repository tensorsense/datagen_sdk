{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation SDK Example usage\n",
    "\n",
    "We are going to generate a dataset of squat videos with instructions to train an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datagen\n",
    "from datagen.core.config import DatagenConfig\n",
    "config = DatagenConfig.from_yaml('./config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of search queries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['how to do squats',\n",
       " 'squat exercises for beginners',\n",
       " 'proper squat form',\n",
       " 'squat variations',\n",
       " 'how to squat correctly']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen.search import get_queries, get_video_info\n",
    "queries = get_queries(config=config, prompt='I want to find instructional videos about how to do squats.', num_queries=5)\n",
    "print(len(queries))\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download video information for each query.\n",
    "\n",
    "There is a lot of useful information to filter the videos at this stage if necessary, but we will only use video ids later.<br>\n",
    "Videos will be deduplicated so we don't need to download the same video multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_video_info(queries, videos_per_query=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id.1</th>\n",
       "      <th>title</th>\n",
       "      <th>formats</th>\n",
       "      <th>thumbnails</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_url</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>vbr</th>\n",
       "      <th>stretched_ratio</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>acodec</th>\n",
       "      <th>abr</th>\n",
       "      <th>asr</th>\n",
       "      <th>audio_channels</th>\n",
       "      <th>query</th>\n",
       "      <th>location</th>\n",
       "      <th>queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4KmY44Xsg2w</td>\n",
       "      <td>4KmY44Xsg2w</td>\n",
       "      <td>The Basic Squat - Balance Exercise - CORE Chir...</td>\n",
       "      <td>[{'format_id': 'sb2', 'format_note': 'storyboa...</td>\n",
       "      <td>[{'url': 'https://i.ytimg.com/vi/4KmY44Xsg2w/3...</td>\n",
       "      <td>https://i.ytimg.com/vi_webp/4KmY44Xsg2w/maxres...</td>\n",
       "      <td>Dr. Natalie Cordova demonstrates how to do a b...</td>\n",
       "      <td>UCW6EenBHb_KF-eaFRE3gXnA</td>\n",
       "      <td>https://www.youtube.com/channel/UCW6EenBHb_KF-...</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>707.089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>opus</td>\n",
       "      <td>93.518</td>\n",
       "      <td>48000</td>\n",
       "      <td>2</td>\n",
       "      <td>squat exercises for beginners</td>\n",
       "      <td>CORE CHIROPRACTIC</td>\n",
       "      <td>[['squat exercises for beginners']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIZ8q1qruKw</td>\n",
       "      <td>AIZ8q1qruKw</td>\n",
       "      <td>How to Perform a PERFECT Squat</td>\n",
       "      <td>[{'format_id': 'sb1', 'format_note': 'storyboa...</td>\n",
       "      <td>[{'url': 'https://i.ytimg.com/vi/AIZ8q1qruKw/o...</td>\n",
       "      <td>https://i.ytimg.com/vi/AIZ8q1qruKw/sd2.jpg?sqp...</td>\n",
       "      <td>Get my book on fixing injury here: \\nhttps://w...</td>\n",
       "      <td>UCyPYQTT20IgzVw92LDvtClw</td>\n",
       "      <td>https://www.youtube.com/channel/UCyPYQTT20IgzV...</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>649.690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>opus</td>\n",
       "      <td>108.711</td>\n",
       "      <td>48000</td>\n",
       "      <td>2</td>\n",
       "      <td>how to do squats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['how to do squats']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C73Y3EsJWIk</td>\n",
       "      <td>C73Y3EsJWIk</td>\n",
       "      <td>Top 10 BEST SQUATS Variations</td>\n",
       "      <td>[{'format_id': 'sb2', 'format_note': 'storyboa...</td>\n",
       "      <td>[{'url': 'https://i.ytimg.com/vi/C73Y3EsJWIk/3...</td>\n",
       "      <td>https://i.ytimg.com/vi_webp/C73Y3EsJWIk/maxres...</td>\n",
       "      <td>Top 10 Best Squat Exercises:\\n\\nHigh Bar Squat...</td>\n",
       "      <td>UCKf0UqBiCQI4Ol0To9V0pKQ</td>\n",
       "      <td>https://www.youtube.com/channel/UCKf0UqBiCQI4O...</td>\n",
       "      <td>479</td>\n",
       "      <td>...</td>\n",
       "      <td>1118.830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>mp4a.40.2</td>\n",
       "      <td>129.483</td>\n",
       "      <td>44100</td>\n",
       "      <td>2</td>\n",
       "      <td>squat variations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['squat variations']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EbOPpWi4L8s</td>\n",
       "      <td>EbOPpWi4L8s</td>\n",
       "      <td>How to Do Squats for Beginners</td>\n",
       "      <td>[{'format_id': 'sb3', 'format_note': 'storyboa...</td>\n",
       "      <td>[{'url': 'https://i.ytimg.com/vi/EbOPpWi4L8s/3...</td>\n",
       "      <td>https://i.ytimg.com/vi/EbOPpWi4L8s/maxresdefau...</td>\n",
       "      <td>How to Do Squats for Beginners. Part of the se...</td>\n",
       "      <td>UCE8wCVw_ZfRw-D6RJ5EXWbw</td>\n",
       "      <td>https://www.youtube.com/channel/UCE8wCVw_ZfRw-...</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>415.467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>opus</td>\n",
       "      <td>106.487</td>\n",
       "      <td>48000</td>\n",
       "      <td>2</td>\n",
       "      <td>squat exercises for beginners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['squat exercises for beginners']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EzvnMZuxGWw</td>\n",
       "      <td>EzvnMZuxGWw</td>\n",
       "      <td>Perfect Squat Form in 3 Steps!</td>\n",
       "      <td>[{'format_id': 'sb2', 'format_note': 'storyboa...</td>\n",
       "      <td>[{'url': 'https://i.ytimg.com/vi/EzvnMZuxGWw/3...</td>\n",
       "      <td>https://i.ytimg.com/vi/EzvnMZuxGWw/maxresdefau...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UCyPYQTT20IgzVw92LDvtClw</td>\n",
       "      <td>https://www.youtube.com/channel/UCyPYQTT20IgzV...</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>1299.342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>opus</td>\n",
       "      <td>127.322</td>\n",
       "      <td>48000</td>\n",
       "      <td>2</td>\n",
       "      <td>proper squat form</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['proper squat form'], ['squat variations']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         id.1  \\\n",
       "0  4KmY44Xsg2w  4KmY44Xsg2w   \n",
       "1  AIZ8q1qruKw  AIZ8q1qruKw   \n",
       "2  C73Y3EsJWIk  C73Y3EsJWIk   \n",
       "3  EbOPpWi4L8s  EbOPpWi4L8s   \n",
       "4  EzvnMZuxGWw  EzvnMZuxGWw   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Basic Squat - Balance Exercise - CORE Chir...   \n",
       "1                     How to Perform a PERFECT Squat   \n",
       "2                      Top 10 BEST SQUATS Variations   \n",
       "3                     How to Do Squats for Beginners   \n",
       "4                     Perfect Squat Form in 3 Steps!   \n",
       "\n",
       "                                             formats  \\\n",
       "0  [{'format_id': 'sb2', 'format_note': 'storyboa...   \n",
       "1  [{'format_id': 'sb1', 'format_note': 'storyboa...   \n",
       "2  [{'format_id': 'sb2', 'format_note': 'storyboa...   \n",
       "3  [{'format_id': 'sb3', 'format_note': 'storyboa...   \n",
       "4  [{'format_id': 'sb2', 'format_note': 'storyboa...   \n",
       "\n",
       "                                          thumbnails  \\\n",
       "0  [{'url': 'https://i.ytimg.com/vi/4KmY44Xsg2w/3...   \n",
       "1  [{'url': 'https://i.ytimg.com/vi/AIZ8q1qruKw/o...   \n",
       "2  [{'url': 'https://i.ytimg.com/vi/C73Y3EsJWIk/3...   \n",
       "3  [{'url': 'https://i.ytimg.com/vi/EbOPpWi4L8s/3...   \n",
       "4  [{'url': 'https://i.ytimg.com/vi/EzvnMZuxGWw/3...   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  https://i.ytimg.com/vi_webp/4KmY44Xsg2w/maxres...   \n",
       "1  https://i.ytimg.com/vi/AIZ8q1qruKw/sd2.jpg?sqp...   \n",
       "2  https://i.ytimg.com/vi_webp/C73Y3EsJWIk/maxres...   \n",
       "3  https://i.ytimg.com/vi/EbOPpWi4L8s/maxresdefau...   \n",
       "4  https://i.ytimg.com/vi/EzvnMZuxGWw/maxresdefau...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Dr. Natalie Cordova demonstrates how to do a b...   \n",
       "1  Get my book on fixing injury here: \\nhttps://w...   \n",
       "2  Top 10 Best Squat Exercises:\\n\\nHigh Bar Squat...   \n",
       "3  How to Do Squats for Beginners. Part of the se...   \n",
       "4                                                NaN   \n",
       "\n",
       "                 channel_id  \\\n",
       "0  UCW6EenBHb_KF-eaFRE3gXnA   \n",
       "1  UCyPYQTT20IgzVw92LDvtClw   \n",
       "2  UCKf0UqBiCQI4Ol0To9V0pKQ   \n",
       "3  UCE8wCVw_ZfRw-D6RJ5EXWbw   \n",
       "4  UCyPYQTT20IgzVw92LDvtClw   \n",
       "\n",
       "                                         channel_url  duration  ...       vbr  \\\n",
       "0  https://www.youtube.com/channel/UCW6EenBHb_KF-...       173  ...   707.089   \n",
       "1  https://www.youtube.com/channel/UCyPYQTT20IgzV...        59  ...   649.690   \n",
       "2  https://www.youtube.com/channel/UCKf0UqBiCQI4O...       479  ...  1118.830   \n",
       "3  https://www.youtube.com/channel/UCE8wCVw_ZfRw-...        97  ...   415.467   \n",
       "4  https://www.youtube.com/channel/UCyPYQTT20IgzV...        60  ...  1299.342   \n",
       "\n",
       "   stretched_ratio  aspect_ratio     acodec      abr    asr  audio_channels  \\\n",
       "0              NaN          1.78       opus   93.518  48000               2   \n",
       "1              NaN          0.56       opus  108.711  48000               2   \n",
       "2              NaN          1.78  mp4a.40.2  129.483  44100               2   \n",
       "3              NaN          1.78       opus  106.487  48000               2   \n",
       "4              NaN          0.56       opus  127.322  48000               2   \n",
       "\n",
       "                           query           location  \\\n",
       "0  squat exercises for beginners  CORE CHIROPRACTIC   \n",
       "1               how to do squats                NaN   \n",
       "2               squat variations                NaN   \n",
       "3  squat exercises for beginners                NaN   \n",
       "4              proper squat form                NaN   \n",
       "\n",
       "                                         queries  \n",
       "0            [['squat exercises for beginners']]  \n",
       "1                         [['how to do squats']]  \n",
       "2                         [['squat variations']]  \n",
       "3            [['squat exercises for beginners']]  \n",
       "4  [['proper squat form'], ['squat variations']]  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For 5 queries times 10 videos per query = 50 videos, we got 28 unique videos\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(config.data_dir / 'video_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download videos and autogenerated subtitles\n",
    "\n",
    "You can change sub languages, formats etc with `yt_dlp_opts` dictionary (refer to https://github.com/yt-dlp/yt-dlp).<br>\n",
    "The SDK is expecting `.mp4` video files (for now), so don't change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen.download_videos import download_videos\n",
    "download_videos(df['id'], config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect segments from video and analyze them with gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byxWus7BwfQ\n",
      "OTyb4YUDYYY\n",
      "w8ZhgecdIAM\n",
      "T6id8FuUcao\n",
      "a3aw-5vDM2E\n",
      "AIZ8q1qruKw\n",
      "C73Y3EsJWIk\n",
      "EbOPpWi4L8s\n",
      "SLOkdLLWj8A\n",
      "EzvnMZuxGWw\n",
      "PJj5shV4uYo\n",
      "MM9ObaAPcv4\n",
      "HgDZlNQrifY\n",
      "LFkinX12jtU\n",
      "LF4zb2SYWjQ\n",
      "xawAf5fXD2c\n",
      "MLoZuAkIyZI\n",
      "TH6jSCGnowI\n",
      "HZilSL4ZNvQ\n",
      "gslEzVggur8\n",
      "cRxg-PUAT6I\n",
      "IB_icWRzi4E\n",
      "my0tLDaWyDU\n",
      "4KmY44Xsg2w\n",
      "rhbIFJj4UYc\n",
      "jhb_nnV29EU\n",
      "iZTxa8NJH2g\n",
      "PPmvh7gBTi0\n"
     ]
    }
   ],
   "source": [
    "from datagen.detect_segments import detect_segments\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# This is the schema that we will extract from each detected segment that will be also used during annotation.\n",
    "# If you want the annotations to focus on the transcript, do not extract too much visual information here that might distract the LLM during annotation.\n",
    "# We will use \"doing_squats\" for filtering,\n",
    "# and overlay_text for annotation, although it might add noise.\n",
    "\n",
    "class SegmentInfo(BaseModel):\n",
    "    '''Information about a segment'''\n",
    "    doing_squats: bool = Field(description='Whether the person is doing squats. Only consider video of people, not renders or cartoons. If a person looks like they are preparing to do squats or standing between reps, consider them also doing squats if they are in a gym setting, wearing sportswear etc.')\n",
    "    overlay_text: str = Field(description='Overlay text that is superimprosed over the image, if present.')\n",
    "    # clothes: str = Field(description='Clothes of the person doing squats in detail.')\n",
    "    # image_description: str = Field(description=\"Describe the image in detail\")\n",
    "\n",
    "\n",
    "segments = []\n",
    "for video in config.get_videos():\n",
    "        print(video.stem)\n",
    "        segments.append(detect_segments(\n",
    "            video_id=video.stem,\n",
    "            segment_info_schema=SegmentInfo,\n",
    "            detection_algorithm=None, # default AdaptiveDetector algorithm is good for most types of video. https://www.scenedetect.com/docs/latest/api/detectors.html\n",
    "            min_duration=1, max_duration=60, # discard too long or too short segments to save some GPT calls\n",
    "            frames_per_segment=1, # how many frames per segment we will use for detection. More frames will be more accurate and capture more information (eg changing overlay text), but also longer and more expensive.\n",
    "            config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      28\n"
     ]
    }
   ],
   "source": [
    "# 28 videos took 14.5 minutes w/1 frame/segment\n",
    "# about 30sec/video\n",
    "!ls tmp/squats/segments | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate the segments from trascript + additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Segment(start_timestamp='00:00:00.000', end_timestamp='00:00:02.800', fps=30.0, segment_info={'doing_squats': True, 'overlay_text': 'TOP THREE ONE LEGGED SQUATS'}, video_id='a3aw-5vDM2E')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = config.get_segments(info_type=SegmentInfo)\n",
    "print(len(segments))\n",
    "# we're only interested in segments where people do squats\n",
    "segments = [x for x in segments if x.segment_info['doing_squats']]\n",
    "print(len(segments))\n",
    "segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen.annotate import generate_annotations\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# This schema will be detected for each segment.\n",
    "# This is the most important part for the annotation, and getting good results requires a lot of experimenting.\n",
    "\n",
    "class QA(BaseModel):\n",
    "    '''\n",
    "    Question and answer about a video segment.\n",
    "    Only write questions and answers about the correctness of the exercises or in which ways the performance in the video was wrong.\n",
    "    '''\n",
    "    question: str = Field(description='Question about the exercise performance in the video')\n",
    "    answer: str = Field(description='Answer about the exercise performance from a trainer.')\n",
    "    quote: str = Field(description='A direct and explicit quote from transcript or on-screen-text. The answer must be directly inferred from this quote.')\n",
    "\n",
    "    # Valid QA:\n",
    "    # - Was the exercise performed correctly? -No.\n",
    "    # - How can I improve my form? -Set your knees wider.\n",
    "    # Invalid QA:\n",
    "    # - Was the exercise perfomed correctly? -There is no information about that.\n",
    "    # - What is written on screen? - The word Hello is written on screen.\n",
    "\n",
    "class SegmentAnnotation(BaseModel):\n",
    "    '''\n",
    "    If there is information about whether the exercise was performed correctly or not, make a QA about it.\n",
    "    If the exercise was performed incorrectly, make one or more QA about in which ways it was performed incorrectly.\n",
    "    If it's not possible to infer whether the exercise was performed correctly, do not output a segment annotation.\n",
    "    Do not output any other kinds of questions and answers.\n",
    "    If no possible such QA could be generated from the explicit information in the transcript or on-screen text, do not output annotation for this segment.\n",
    "    Output at most one annotation per segment.\n",
    "    '''\n",
    "    correct: Optional[bool] = Field(description='Whether the exercise was performed correctly. If there is no information about that, do not output this field.')\n",
    "    incorrect_reasons: Optional[str] = Field(description='If the exercise was performed incorrectly, the reasons that were given about why was the performance was incorrect. If there is no information about that, do not output this field.')\n",
    "    qa: list[QA]\n",
    "\n",
    "annotations = generate_annotations(segments=segments, config=config, annotation_schema=SegmentAnnotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping AIZ8q1qruKw\n",
      "skipping iZTxa8NJH2g\n",
      "Total segments: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'start_timestamp': '00:00:26.933',\n",
       " 'end_timestamp': '00:00:28.467',\n",
       " 'segment_annotation': {'correct': False,\n",
       "  'incorrect_reasons': 'Incorrect stance',\n",
       "  'qa': [{'question': 'Was the exercise performed correctly?',\n",
       "    'answer': 'No',\n",
       "    'quote': 'X, âœ“'}]},\n",
       " 'video_id': 'OTyb4YUDYYY',\n",
       " 'id': 'OTyb4YUDYYY_0',\n",
       " 'video_path': 'OTyb4YUDYYY_0.mp4'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen.annotate import aggregate_annotations\n",
    "\n",
    "# here we filter the segments to only leave those that have correctness information and some QA\n",
    "filter_func = lambda seg: seg['correct'] is not None and len(seg['qa'])\n",
    "annotations = aggregate_annotations(config, filter_func=filter_func)\n",
    "print('Total segments:', len(annotations))\n",
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(config.data_dir / 'annotations.json', 'w') as f:\n",
    "    json.dump(annotations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last step is to cut video clips for these segments from original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:22<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from datagen.cut_videos import cut_videos\n",
    "cut_videos(annotations, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as a result we generated:\n",
    "- `<data_dir>/clips/` with video clips that you can use for training\n",
    "- `<data_dir>/annotations.json` with list of items with fields:\n",
    "    - video_id: 11-char youtube video id (youtube.com/watch?v=<id>)\n",
    "    - start_timestamp/end_timestamp of the clip relative to the youtube video it's taken from\n",
    "    - video_path of the clip relative to `<data_dir>/clips/`\n",
    "    - segment_annotation that you can use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
